敏捷开发计划 (3-Sprint)
Sprint 1: 核心能力层构建与本地反射验证
周期: 2周
目标: 完成新增硬件的驱动适配与L1原子技能层封装，并实现基础的L2本地事件响应逻辑。
关键交付物:
硬件驱动: 在boards/ALichuangTest/下，完成IMU、舵机、振动马达等新增驱动的开发与单元测试。
原子技能层: 在main/skills/目录下，实现motion.h, animation.h, vibration.h等核心模块，提供标准化的、异步非阻塞的接口。
本地交互逻辑初版:
event_engine: 实现对touch_repetitive和event_inverted等关键事件的识别。
emotion_engine & reaction_engine: 实现基础框架，打通从事件识别到调用原子技能执行本地反射的离线链路。
验收标准: 设备在无网络状态下，对快速敲击、倒置等物理操作，能做出即时、正确的、由多个原子技能组合而成的反射动作。
Sprint 2: 情感系统完善与端云链路打通
周期: 2周
目标: 构建完整的本地情感反应系统，并实现端侧与云端后台的双向通信与指令调度。
关键交付物:
情感反应系统: 完善reaction_engine，为所有社交情感类事件，根据四象限情感状态填充多样化的反应池。
端云通信协议v1.0: 与后台工程师共同定义并固化事件上报与指令下发的JSON数据结构。
应用层通信: 在application.cc中，实现结构化事件的上报和云端指令的接收、解析。
智能动作队列: 创建action_queue模块，用于统一调度本地P2级反射和云端P1级指令，并实现高优先级中断规则。
验收标准: 后台能接收并正确解析端侧上报的各类事件。可通过后台工具向设备发送结构化动作指令，设备能正确执行，并能演示P1指令中断P2反射的场景。
Sprint 3: AI能力整合与Demo冲刺
周期: 2周
目标: 完成与后台AI逻辑的全链路联调，完整复现核心演示场景，并进行体验优化。
关键交付物:
全链路功能联调:
与后台工程师协作，完成对**“一句话变脸”**场景的联调，验证语音对情感状态的实时影响。
完成对**“一张画背后的心情”**场景的联调，验证摄像头视觉理解、混合记忆检索与LLM推理的完整通路。
交互体验打磨: 实现并调优**“过渡与冷却 (Cooldown)”**机制，确保动作切换的自然流畅。优化所有演示所需的动画、音效、灯光、振动效果。
稳定性与演示准备: 对所有核心Use Case进行反复测试，修复已知Bug，固化最终的演示脚本和流程。
验收标准: 能够稳定、流畅地、完整地复现为潜在投资人设计的所有核心演示场景。